<!DOCTYPE html>
<html>
<head>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-155704029-2"></script>
    

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-155704029-2');
</script>
  <meta charset="utf-8">
<link  rel="stylesheet" type="text/css" href="main.css">
 <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    
   <h2 class="top"> <span class="bigger1"> Jeremy Steffman</span></h2>
     
    <h3 class="top">Northwestern Linguistics</h3>

<div class="square1"></div>
    
    <ul class="nav">
        <div id="navigation">
                <li class="top"style="width:25%"><a href="index.html" class="current">home</a></li>
             <li class="top"style="width:25%"><a href="research.html">vita</a></li>
            <li class="top"style="width:25%"><a class="top" href="teaching.html">teaching</a></li>
        </div>
</ul>
    </head>

<body>


        <p class ="research"> 
            
              <br>  <br>  <br>  <br> 
            
   
              <img src="docs/img.png" style="width: 150px;filter: grayscale(10%);margin-top: 60px;float: right;margin-right: 350px"> <br> <br> 


      <span style="font-size:130%">&#9993 </span> <br>
               <span style="unicode-bidi:bidi-override; direction: rtl; font-size: 115%"  data-text="ude.nretsewhtron@namffets.ymerej"></span>
    <br>  
     <br> 
      <span style="font-size:140%":>&#9998 </span>   <br> 
                Northwestern University <br>
                Dept. of Linguistics <br>
                2016 Sheridan Road <br>
                Evanston, IL 60208

           <br><br>
      <span style="font-size:140%":>&#x261E; </span> 
            <a href="cv.html"> CV </a> 
            <br> <br>  <br>  
    
              
            <hr>
        
     <br>  <br> 
          
    

 <p class= "research"> I'm a psycholinguist/phonetician/laboratory-phonologist, and a postdoctoral fellow at Northwestern University where I work in 
    the <a href=https://www.prosodylab.linguistics.northwestern.edu>Prosody and Speech Dynamics Lab</a>. Prior to this, I received my PhD in Linguistics from <a href=https://linguistics.ucla.edu> UCLA</a>. 
    
       <br>  <br> 
    
    My research program centers on examining how prosodic/intonational structure, and its phonetic correlates, influence speech processing.  <a href=docs/Steffman_2020.pdf> My dissertation </a> <i>Prosodic prominence in vowel perception and spoken language processing</i>, explores one domain where these questions are especially interesting. My postdoc research is focused on how speakers produce, represent and perceive intonational patterns - see <a href= docs/Steffman_Cole_MidPhon_2021.pdf>here</a> for some recent work on this topic. 
     
     
    <br> <br> 
     
     
    More broadly, I'm interested in speech perception, prosody, and processing. In another strand of research, I describe phonetic structure and patterns in language, mostly from acoustic data.
     
    
        <br><br>
        Check out the vita tab for a full list of publications and presentations. Scroll down for a list of recent activities, and some current projects. Don't hesitate to email me for pdfs of any posters or slides. 
        
        <br><br><br><br><br><br><br><br>
    
        
    
    
     <span style= "font-size:110%; color: #3b555e">Recent and upcoming</span>     

        <ul class="news2">
    
           
                
    <li class ="news2"> Collaborators and myself will be presenting at <a href= https://my.eventbuizz.com/event/1st-international-conference-on-tone-and-intonation--tai--2021/detail>TAI</a>: 
        <br><br>
    
        Katsuda, H. & Steffman, J.
        <i>Prominence-boundary interactions in speech perception: evidence from Japanese vowel length </i> 
              <br><br>
        
        Cole, J. & Steffman, J. <i>The primacy of the rising/non-rising dichotomy in American English intonational tunes</i>   </li>    
       
            
                <li class ="news2"> Collaborators and myself will be presenting at <a href= https://www.linguisticsociety.org/event/lsa-2022-annual-meeting>LSA</a>: 
        <br><br>
    
         Steffman, J., Cox, L., Cole, J. & Shattuck-Hufnagel, S.
        <i>Nuclear Tunes lost and found: Modeling intonational tunes in American English with labeled vs. unlabeled data</i> 
                    
         <br><br>
             
        Weller, J., Steffman, J., Cortés, F. & Mantenuto, I. 
        <i>Glottalization and Tonal Contrasts in San Sebastián del Monte Mixtec Rearticulated Vowels</i> 
            
        <br><br>
  
                    
                        
            
      <li class ="news2">  My paper "Rhythmic and speech rate effects in the perception of durational cues." is out now in<i> Attention, Perception & Psychophysics</i>.  <a href= https://rdcu.be/coeWm>[view only link]</a>  <a href=  https://link.springer.com/article/10.3758/s13414-021-02334-w>[publisher link]</a> </li> 
            
   
    <li class ="news2">  My paper "Contextual prominence in vowel perception: Testing listener sensitivity to sonority expansion and hyperarticulation" is out now in JASA Express Letters. <a href= https://asa.scitation.org/doi/10.1121/10.0003984>[link]</a>  </li>
            
        
            
            
          </ul>
                 
    
    
     <br><br>  <br><br> <br><br> <br>  <br> <br><br> <br><br> <br><br> <br> <br><br> <br> <br><br><br><br> <br> <br><br> <br> <br><br> 
     <p class= "research">  
    <span style= "font-size:110%; color: #3b555e">Some current projects</span>   
          


    <ul class="news2">
              
    <li class="news2"> The role of different aspects of phonological and lexical organization in speech perception: disentangling and comparing the influence of biphone probability and neighborhood density in phonetic categorization, and online processing using eyetracking - in collaboration with Megha Sundara. See <a href= docs/Steffman_Sundara.pdf> [here]</a> for a manuscript.</li>    
                   
    <li class="news2">  The influence of intonational structure and context on listeners' perception of durational cues, and processing of pitch accent in word recognition in Tokyo Japanese - in collaboration with Hironori Katsuda.                  
              
    <li class="news2"> The articulation and acoustics of voiced aspirated sounds in Yemba (Dschang), a language spoken in Cameroon - in collaboration with Matt Faytak and Rolain Tankou. Yemba has voiced and fully aspirated (not breathy-voiced) segments, for example [ndʰù] 'distant relative' (n.b. NOT [ndʱù]), cf. [ndù] 'river'. 
        
    <br><br> 
    We're using EGG to explore laryngeal articulation and timing patterns for voicing in these segments. We're also intersted in how voice quality for voiced+aspirated sounds differs from their unaspirated counterparts. To this end, were analyzing acoustic voice quality measures in tandem with EGG parameters. See <a href= docs/Faytak-Steffman-Tankou_ACAL5152.pdf> [here]</a> for a recent presentation. 
        
                <br><br> 
    I'm also working with Jae Weller to test how both aspiration and voicing in Yemba influence the articulation and acoustics of the following vowel.</li> 
        
    <li class="news2">  The influence of tonal cues to prosodic phrasing on the perception of segmental contrasts in Seoul Korean, as a function of domain initial strengthening - in collaboration with Sahyang Kim, Taehong Cho and Sun-Ah Jun. 
        
    <li class="news2"> Phonetic structure in San Sebastián del Monte Mixtec, including the realization of so-called rearticulated vowels and glottalization - in collaboration with Iara Mantenuto and Félix Cortés.
                       
           
     <!--    <li class="news2"> The role of pitch and durational cues to focus in the processing of contrastive pitch accents in English - in collaboration with Chie Nakamura and Sun-Ah Jun. Previous work has shown that listeners make predictions about upcoming information based on focus structure. For example, if I tell you "I wore a green hat, my friend wore a BLUE ..." you might expect the blue object will be a hat because the color term is in contrast. We're interested what phonetic properties inform this sort of predictive processing - more specifically - how do pitch cues and duration serve independently to shape listeners' predictions? How do they combine? We're exploring these questions with eyetracking.  -->
        
        
</ul>

</body>

    
<div class="footer">
    © Jeremy Steffman <script type="text/javascript">
  document.write(new Date().getFullYear());
</script>. All rights reserved. 
</div>

</html>


