<!DOCTYPE html>
<html>
<head>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-155704029-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-155704029-2');
</script>
  <meta charset="utf-8">
<link  rel="stylesheet" type="text/css" href="main.css">
 <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    
   <h2 class="top"> <span class="bigger1"> Jeremy Steffman</span></h2>
     
    <h3 class="top">UCLA Linguistics</h3>

<div class="square1"></div>
    
    <ul class="nav">
        <div id="navigation">
                <li class="top"style="width:25%"><a href="index.html" class="current">home</a></li>
             <li class="top"style="width:25%"><a href="research.html">vita</a></li>
            <li class="top"style="width:25%"><a class="top" href="teaching.html">teaching</a></li>
        </div>
</ul>
    
    </head>

<body>


        <p class ="research"> 
            
              <br>  <br>  <br>  <br> 
            
   
              <img src="docs/img.png" style="width: 150px;filter: grayscale(10%);margin-top: 60px;float: right;margin-right: 350px"> <br> <br> 


      <span style="font-size:130%">&#9993 </span> <br>
               <span style="unicode-bidi:bidi-override; direction: rtl; font-size: 130%"  data-text="ude.alcu@namffetsj"></span>
    <br>  
     <br> 
      <span style="font-size:140%":>&#9998 </span>   <br> 
                UCLA Dept. of Linguistics <br>
                3125 Campbell Hall <br>
                Los Angeles, CA 90095-1543

           <br><br>
      <span style="font-size:140%":>&#x261E; </span> 
            <a href="cv.html"> CV </a> 
            <br> <br>  <br>  
    
              
            <hr>
        
     <br>  <br> 
          

        <p class= "research"> I'm a PhD candidate in the Dept. of Linguistics at <a href=http://linguistics.ucla.edu/>UCLA</a> and a member of the <a href=http://phonetics.linguistics.ucla.edu/> UCLA Phonetics Lab</a>. <br>  <br> 
    

 I'm interested in phonetics, speech perception, prosody, and psycholinguistics. My central research program focuses on how prosodic/intonational structure, and its phonetic correlates, influence speech processing. I seek to address questions such as: 

</p>

<ul class="news2">
    <li class="news2"> How does prosodic organizaiton of the speech signal influence listeners' perception of segmental contrasts?  <a href= https://asa.scitation.org/doi/10.1121/1.5111772> [Steffman 2019b] </a>  How do these effects relate to other perceptual processes? <a href=https://www.sciencedirect.com/science/article/pii/S0095447018301177/>[Steffman 2019a]</a> <a href= https://asa.scitation.org/doi/10.1121/1.5126107> [Steffman & Jun 2019]</a> </li>  
    
     <li class="news2">What can these findings tell us more broadly about speech perception, and the role of different types of information in speech processing? </li>
    
</ul>
   
<br><br><br><br><br><br><br><br><br><br>
    <p class= "research">
        
My dissertation (in progress) explores one particular domain where these questions are especially interesting, testing the effects of prosodic prominence on listeners' perception of vowel contrasts. See  <a href= docs/Steffman_Prominence.pdf> [here]</a> for a manuscript based on one chapter of my dissertation. 

             
 <br><br>
        
More generally, I'm interested in describing phonetic structure and patterns in language, mostly from acoustic data. 
        
        <br><br>
        Check out the vita tab for a full list of publications and presentations. Scroll down for a list of recent activities, and some current projects. Don't hesitate to email me for pdfs of any posters or slides. 
        
        <br><br>
    
        
        <br><br><br><br><br><br>
    
    
     <span style= "font-size:110%; color: #3b555e">Recent and upcoming</span>     

        <ul class="news2">
        <li class ="news2"> Collaborators and myself presented two posters at virtual LabPhon: 1) A component of my disseratation work "Prominence effects on the processing of spectral cues: testing sonority expansion in perception" <a href= docs/Steffman_LabPhon2020.pdf>[pdf here] </a> and 2) An acoustic and EGG study of voiced aspirated sounds in Yemba, in collaboration with Matt Faytak and Rolain Tankou. <a href= docs/Faytak_Steffman_Tankou_LabPhon2020.pdf>[pdf here] </a> </li>
                    
            
        <li class ="news2">  Hironori Katsuda presented some of our recent work on Japanese intonational influences in perception at Speech Prosody (held vritually). <a href= docs/Katsuda_Steffman_2020_Speech_Prosody.pdf>[pdf here] </a></li>
                    
        <li class ="news2">  CUNY 2020: I presented a poster on a component of my disseration work, testing how phrase-level prominence influences perception online: "Prominence effects on pre-lexical processing: time-course evidence from vowel perception". <a href= docs/Steffman_CUNY2020.pdf> [pdf here] </a></li>
            
        <li class ="news2">  WCCFL 2020:  Sun-Ah Jun and I presented some recent work on prominence effects in perception: "Prosodic prominence in speech perception: the influence of focus structure on the perception of durational and spectral cues". <a href= docs/wccfl2020.pdf> [slides here]</a> </li> 
         <br><br>

   
    </ul>
    
    <br> <br><br> <br><br>  <br><br> <br><br> <br>  <br> <br><br> <br><br> <br><br>   <br> <br> <br> <br> 
     <p class= "research">  
    <span style= "font-size:110%; color: #3b555e">Some other current projects</span>   
          


          <ul class="news2">
              
    <li class="news2"> The articulation and acoustics of voiced aspirated sounds in Dschang (Yemba), a language spoken in Cameroon (in collaboration with Matt Faytak and Rolain Tankou). Dschang has voiced and fully aspirated (not breathy-voiced) segments, for example [ndʰù] 'distant relative' (n.b. NOT [ndʱù]), cf. [ndù] 'river'. 
        
        <br><br> 
    We're using EGG to explore laryngeal articulation and timing patterns for voicing in these segments. We're also intersted in how voice quality for voiced+aspirated sounds differs from their unaspirated counterparts. To this end, were analyzing acoustic voice quality measures in tandem with EGG parameters. 
        
    
    <li class="news2"> The role of different aspects of phonological and lexical organization in speech perception: disentangling and comparing the influence of biphone probability and neighborhood density in phonetic categorization, and online processing using eyetracking (in collaboration with Megha Sundara). 
                   
    <li class="news2">  The influence of intonational structure and context on listeners' perception of durational cues, and processing of pitch accent in Tokyo Japanese (in collaboration with Hironori Katsuda). 
    
    
    <li class="news2"> The role of different aspects of phonological and lexical organization in speech perception: disentangling and comparing the influence of biphone probability and neighborhood density in phonetic categorization (in collaboration with Megha Sundara). We're currently in the process testing how these effects play out online with eyetracking. 
         
    <li class="news2">  The influence of tonal cues to prosodic phrasing on the perception of segmental contrasts in Seoul Korean, as a function of domain initial strenghtning (in collaboration with Sun-Ah Jun, Taehong Cho and Sahyang Kim). 
           
    <li class="news2"> The role of pitch and durational cues to focus in the processing of contrastive pitch accents in English (in collaboration with Chie Nakamura and Sun-Ah Jun). Previous work has shown that listeners make predictions about upcoming information based on focus structure. For example, if I tell you "I wore a green hat, my friend wore a BLUE ..." you might expect the blue object will be a hat because the color term is in contrast. We're interested what phonetic properties inform this sort of predictive processing - more specifically - how do pitch cues and duration serve independently to shape listeners' predictions? How do they combine? We're exploring these questions with eyetracking.  
        
        

</ul>
      

<br> <br><br><br> <br><br><br> <br><br>
    
  </div>  </div> 

</body>

    
<div class="footer">
    © Jeremy Steffman <script type="text/javascript">
  document.write(new Date().getFullYear());
</script>. All rights reserved. 
</div>

</html>


